
<!DOCTYPE html>

<html lang="zh_CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Lidar Perception &#8212; Sphinx documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx13.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/tabs.js"></script>
    <script src="../../../_static/translations.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <link rel="canonical" href="https://www.sphinx-doc.org/en/master/modules/perception/lidar/README.html" />
    <link rel="search" type="application/opensearchdescription+xml"
          title="在 Sphinx documentation 中搜索"
          href="../../../_static/opensearch.xml"/>
    <link rel="shortcut icon" href="../../../_static/favicon.svg"/>
    <link rel="index" title="索引" href="../../../genindex.html" />
    <link rel="search" title="搜索" href="../../../search.html" />
    <link rel="next" title="Lidar Perception" href="README_6.0.html" />
    <link rel="prev" title="Camera Perception" href="../camera/README.html" />
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300,400,700'
          rel='stylesheet' type='text/css' />
 
    <style type="text/css">
      table.right { float: right; margin-left: 20px; }
      table.right td { border: 1px solid #ccc; }
      
    </style>
    <script>
      // intelligent scrolling of the sidebar content
      $(window).scroll(function() {
        var sb = $('.sphinxsidebarwrapper');
        var win = $(window);
        var sbh = sb.height();
        var offset = $('.sphinxsidebar').position()['top'];
        var wintop = win.scrollTop();
        var winbot = wintop + win.innerHeight();
        var curtop = sb.position()['top'];
        var curbot = curtop + sbh;
        // does sidebar fit in window?
        if (sbh < win.innerHeight()) {
          // yes: easy case -- always keep at the top
          sb.css('top', $u.min([$u.max([0, wintop - offset - 10]),
                                $(document).height() - sbh - 200]));
        } else {
          // no: only scroll if top/bottom edge of sidebar is at
          // top/bottom edge of window
          if (curtop > wintop && curbot > winbot) {
            sb.css('top', $u.max([wintop - offset - 10, 0]));
          } else if (curtop < wintop && curbot < winbot) {
            sb.css('top', $u.min([winbot - sbh - offset - 20,
                                  $(document).height() - sbh - 200]));
          }
        }
      });
    </script>

  </head><body>
<div class="pageheader">
  <ul>
    <li><a href="../../../README.html">Home</a></li>
    <li><a href="../../../docs/quickstart/README.html">Get it</a></li>
    <li><a href="../../../contents.html">Docs</a></li>
    <li><a href="../../../development/index.html">Extend</a></li>
  </ul>
  <div>
    <a href="../../../README.html">
      <img src="../../../_static/sphinx.png" alt="Apollo Doc" />
    </a>
  </div>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>导航</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="总目录"
             accesskey="I">索引</a></li>
        <li class="right" >
          <a href="README_6.0.html" title="Lidar Perception"
             accesskey="N">下一页</a> |</li>
        <li class="right" >
          <a href="../camera/README.html" title="Camera Perception"
             accesskey="P">上一页</a> |</li>
        <li><a href="../../../index.html">Apollo home</a>&#160;|</li>
        <li><a href="../../../contents.html">Documentation</a> &#187;</li>

        <li class="nav-item nav-item-this"><a href="">Lidar Perception</a></li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../../../contents.html">目录</a></h3>
  <ul>
<li><a class="reference internal" href="#">Lidar Perception</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#architecture">Architecture</a><ul>
<li><a class="reference internal" href="#attention-module">Attention Module</a></li>
<li><a class="reference internal" href="#pillar-level-supervision">Pillar-level supervision</a></li>
</ul>
</li>
<li><a class="reference internal" href="#results">Results</a></li>
<li><a class="reference internal" href="#online">Online</a></li>
<li><a class="reference internal" href="#launch">Launch</a></li>
<li><a class="reference internal" href="#reference">Reference</a></li>
</ul>
</li>
</ul>

  <h4>上一个主题</h4>
  <p class="topless"><a href="../camera/README.html"
                        title="上一章">Camera Perception</a></p>
  <h4>下一个主题</h4>
  <p class="topless"><a href="README_6.0.html"
                        title="下一章">Lidar Perception</a></p>
  <div role="note" aria-label="source link">
    <h3>本页</h3>
    <ul class="this-page-menu">
      <li><a href="../../../_sources/modules/perception/lidar/README.md.txt"
            rel="nofollow">显示源代码</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">快速搜索</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="转向" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section class="tex2jax_ignore mathjax_ignore" id="lidar-perception">
<h1>Lidar Perception<a class="headerlink" href="#lidar-perception" title="永久链接至标题">¶</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="永久链接至标题">¶</a></h2>
<p>In Apollo 7.0, a new LiDAR-based obstacle detection model is provided named Mask-Pillars based on PointPillars, which improves the original version in two aspects. The first one is that a residual attention module is introduced into the encoder of the backbone to learn a mask and to enhance the feature map in a residual way. The second one is that a pillar-level supervision is applied after decoder of the backbone which is only performed in the training stage. The training data for pillar-level supervision is generated by composing the distribution of foreground obstacle pillars. From the experimental validation, Mask-Pillars achieves higher performance than PointPillars on both Kitti and Waymo datasets, especially the recall on obstacles.</p>
</section>
<section id="architecture">
<h2>Architecture<a class="headerlink" href="#architecture" title="永久链接至标题">¶</a></h2>
<p>Here we mainly focus on the modifications based on PointPillars:</p>
<section id="attention-module">
<h3>Attention Module<a class="headerlink" href="#attention-module" title="永久链接至标题">¶</a></h3>
<p>Although LiDAR can collect high-quality point cloud data, some obstacles may have a small number of point clouds due to occlusion or distance. Therefore, we introduce an attention layer on FPN encoder module to enhance the features refer to <a class="reference external" href="https://arxiv.org/abs/1704.06904">Residual Attention Network for Image Classification</a>. Since FPN has three feature maps with different resolutions, our attention module also acts on three feature maps at the same time. More details about the network architecture can refer to figure below，S represent Sigmoid，F function is shown as Formula 1：</p>
<div class="math notranslate nohighlight">
\[
F(x) = (1 + M(x)) * T(x)
\tag{1}
\]</div>
<p><span class="math notranslate nohighlight">\(T(x)\)</span>is the output of backbone，<span class="math notranslate nohighlight">\(M(x)\)</span>is the output of attention module.</p>
</section>
<section id="pillar-level-supervision">
<h3>Pillar-level supervision<a class="headerlink" href="#pillar-level-supervision" title="永久链接至标题">¶</a></h3>
<p>In order to improve the recall of the network, we introduce a pillar-level supervision mechanism in the training stage. We notice that the segmentation algorithms always have high recall rates because of the pixel level supervision. Therefore, we borrow the idea of segmentation network by adding a pillar-level supervision of foreground pillars that representing obstacles. The feature maps before feeding into the detection module are supervised by the pillar supervision data, which are represented as obstacle distributions. The supervision data are simply generated by composing the Guassion distributions of obstacle pillars of the training point cloud.</p>
<p>The network structure of the final FPN is shown in the figure below</p>
<div align=center>
<img src="../../../docs/specs/images/3d_obstacle_perception/lidar_network.png" alt="图片名称" width="60%" />
</div>
</section>
</section>
<section id="results">
<h2>Results<a class="headerlink" href="#results" title="永久链接至标题">¶</a></h2>
<p>We apply the MMDetection3D framework for training. On the KITTI validation set, the results are as shown in the below table. The results of PointPillars comes from <a class="reference external" href="https://github.com/open-mmlab/mmdetection3d/blob/master/configs/pointpillars/README.md">mmdetction3d</a></p>
<div align=center>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Method</p></th>
<th class="text-align:center head"><p>3DmAP <br> Mod.</p></th>
<th class="text-align:center head"><p>Car <br> Easy Mod. Hard</p></th>
<th class="text-align:center head"><p>Pedestrian <br> Easy Mod. Hard</p></th>
<th class="text-align:center head"><p>Cyclist <br> Easy Mod. Hard</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>PointPillars</p></td>
<td class="text-align:center"><p>60.11</p></td>
<td class="text-align:center"><p>85.41     73.98	 67.76</p></td>
<td class="text-align:center"><p>52.02	      46.40        42.48</p></td>
<td class="text-align:center"><p>78.72	   59.95	57.25</p></td>
</tr>
<tr class="row-odd"><td><p>Ours</p></td>
<td class="text-align:center"><p>62.07</p></td>
<td class="text-align:center"><p>86.13     76.74	 74.14</p></td>
<td class="text-align:center"><p>50.79	      45.59	       41.50</p></td>
<td class="text-align:center"><p>83.91	   63.87	61.05</p></td>
</tr>
</tbody>
</table>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Method</p></th>
<th class="text-align:center head"><p>BEVmAP <br> Mod.</p></th>
<th class="text-align:center head"><p>Car <br> Easy Mod. Hard</p></th>
<th class="text-align:center head"><p>Pedestrian <br> Easy Mod. Hard</p></th>
<th class="text-align:center head"><p>Cyclist <br> Easy Mod. Hard</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>PointPillars</p></td>
<td class="text-align:center"><p>67.76</p></td>
<td class="text-align:center"><p>89.93     86.57	 85.20</p></td>
<td class="text-align:center"><p>59.08	      53.36	       48.42</p></td>
<td class="text-align:center"><p>80.93	   63.34	60.06</p></td>
</tr>
<tr class="row-odd"><td><p>Ours</p></td>
<td class="text-align:center"><p>69.49</p></td>
<td class="text-align:center"><p>89.85     87.15	 85.55</p></td>
<td class="text-align:center"><p>58.29	      53.87	       49.98</p></td>
<td class="text-align:center"><p>85.13	   67.43	63.85</p></td>
</tr>
</tbody>
</table>
</div>
<p>The detection visualization on KITTI data of PointPillars and our model are shown as below. It can be seen that our model has better detection performance. We can see that truncated and occluded vehicles are recalled by our model.</p>
<div align=center>
<img src="../../../docs/specs/images/3d_obstacle_perception/lidar_detection_compare.png" alt="图片名称" width="60%" />
</div>
</section>
<section id="online">
<h2>Online<a class="headerlink" href="#online" title="永久链接至标题">¶</a></h2>
<p>Here, we use libtorch for online deployment and use the torch.jit.trace function of pytorch. We divide the original model into five parts. For more details, please refer to the code：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;modules/perception/lidar/lib/detector/point_pillars_detection/point_pillars.cc&quot;</span>
</pre></div>
</div>
</section>
<section id="launch">
<h2>Launch<a class="headerlink" href="#launch" title="永久链接至标题">¶</a></h2>
<p>In order to facilitate the extension of Apollo models, we refactor the detection module that allows more pluggable detection models. To choose a specific model, you only need to modify corresponding configuration files. The configuration files are referred to:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">modules</span><span class="o">/</span><span class="n">perception</span><span class="o">/</span><span class="n">production</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">perception</span><span class="o">/</span><span class="n">lidar</span><span class="o">/</span><span class="n">models</span><span class="o">/</span><span class="n">lidar_obstacle_pipeline</span><span class="o">/</span>
</pre></div>
</div>
<p>There are several directories in the path, which are related to corresponding sensors. For LiDAR sensor, you could modify the value of key “detector” in “lidar_obstacle_detection.conf” file to switch the LiDAR-based detection model.</p>
</section>
<section id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li><p>MMDetection3D: OpenMMLab next-generation platform for general 3D object detection <a class="reference external" href="https://github.com/open-mmlab/mmdetection3d">https://github.com/open-mmlab/mmdetection3d</a></p></li>
</ul>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>导航</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="总目录"
             >索引</a></li>
        <li class="right" >
          <a href="README_6.0.html" title="Lidar Perception"
             >下一页</a> |</li>
        <li class="right" >
          <a href="../camera/README.html" title="Camera Perception"
             >上一页</a> |</li>
        <li><a href="../../../index.html">Apollo home</a>&#160;|</li>
        <li><a href="../../../contents.html">Documentation</a> &#187;</li>

        <li class="nav-item nav-item-this"><a href="">Lidar Perception</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; 版权所有 2021, xinetzone.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.2.0.
    </div>
  </body>
</html>