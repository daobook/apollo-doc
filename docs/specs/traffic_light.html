
<!DOCTYPE html>

<html lang="zh_CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Traffic Light Perception &#8212; Sphinx documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx13.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/tabs.js"></script>
    <script src="../../_static/translations.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <link rel="canonical" href="https://www.sphinx-doc.org/en/master/docs/specs/traffic_light.html" />
    <link rel="search" type="application/opensearchdescription+xml"
          title="在 Sphinx documentation 中搜索"
          href="../../_static/opensearch.xml"/>
    <link rel="shortcut icon" href="../../_static/favicon.svg"/>
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="交通信号灯感知" href="traffic_light_cn.html" />
    <link rel="prev" title="参考线平滑设定" href="reference_line_smoother_cn.html" />
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300,400,700'
          rel='stylesheet' type='text/css' />
 
    <style type="text/css">
      table.right { float: right; margin-left: 20px; }
      table.right td { border: 1px solid #ccc; }
      
    </style>
    <script>
      // intelligent scrolling of the sidebar content
      $(window).scroll(function() {
        var sb = $('.sphinxsidebarwrapper');
        var win = $(window);
        var sbh = sb.height();
        var offset = $('.sphinxsidebar').position()['top'];
        var wintop = win.scrollTop();
        var winbot = wintop + win.innerHeight();
        var curtop = sb.position()['top'];
        var curbot = curtop + sbh;
        // does sidebar fit in window?
        if (sbh < win.innerHeight()) {
          // yes: easy case -- always keep at the top
          sb.css('top', $u.min([$u.max([0, wintop - offset - 10]),
                                $(document).height() - sbh - 200]));
        } else {
          // no: only scroll if top/bottom edge of sidebar is at
          // top/bottom edge of window
          if (curtop > wintop && curbot > winbot) {
            sb.css('top', $u.max([wintop - offset - 10, 0]));
          } else if (curtop < wintop && curbot < winbot) {
            sb.css('top', $u.min([winbot - sbh - offset - 20,
                                  $(document).height() - sbh - 200]));
          }
        }
      });
    </script>

  </head><body>
<div class="pageheader">
  <ul>
    <li><a href="../../README.html">Home</a></li>
    <li><a href="../quickstart/README.html">Get it</a></li>
    <li><a href="../../contents.html">Docs</a></li>
    <li><a href="../../development/index.html">Extend</a></li>
  </ul>
  <div>
    <a href="../../README.html">
      <img src="../../_static/sphinx.png" alt="Apollo Doc" />
    </a>
  </div>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>导航</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="总目录"
             accesskey="I">索引</a></li>
        <li class="right" >
          <a href="traffic_light_cn.html" title="交通信号灯感知"
             accesskey="N">下一页</a> |</li>
        <li class="right" >
          <a href="reference_line_smoother_cn.html" title="参考线平滑设定"
             accesskey="P">上一页</a> |</li>
        <li><a href="../../index.html">Apollo home</a>&#160;|</li>
        <li><a href="../../contents.html">Documentation</a> &#187;</li>

        <li class="nav-item nav-item-this"><a href="">Traffic Light Perception</a></li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../../contents.html">目录</a></h3>
  <ul>
<li><a class="reference internal" href="#">Traffic Light Perception</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
</ul>
</li>
<li><a class="reference internal" href="#pipeline">Pipeline</a><ul>
<li><a class="reference internal" href="#pre-process">Pre-process</a><ul>
<li><a class="reference internal" href="#input-output">Input/Output</a><ul>
<li><a class="reference internal" href="#input">Input</a></li>
<li><a class="reference internal" href="#output">Output</a></li>
</ul>
</li>
<li><a class="reference internal" href="#camera-selection">Camera Selection</a></li>
<li><a class="reference internal" href="#image-sync">Image Sync</a></li>
</ul>
</li>
<li><a class="reference internal" href="#process">Process</a><ul>
<li><a class="reference internal" href="#id1">Input/Output</a><ul>
<li><a class="reference internal" href="#id2">Input</a></li>
<li><a class="reference internal" href="#id3">Output</a></li>
</ul>
</li>
<li><a class="reference internal" href="#rectifier">Rectifier</a></li>
<li><a class="reference internal" href="#recognizer">Recognizer</a></li>
<li><a class="reference internal" href="#reviser">Reviser</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>上一个主题</h4>
  <p class="topless"><a href="reference_line_smoother_cn.html"
                        title="上一章">参考线平滑设定</a></p>
  <h4>下一个主题</h4>
  <p class="topless"><a href="traffic_light_cn.html"
                        title="下一章">交通信号灯感知</a></p>
  <div role="note" aria-label="source link">
    <h3>本页</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/docs/specs/traffic_light.md.txt"
            rel="nofollow">显示源代码</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">快速搜索</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="转向" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section class="tex2jax_ignore mathjax_ignore" id="traffic-light-perception">
<h1>Traffic Light Perception<a class="headerlink" href="#traffic-light-perception" title="永久链接至标题">¶</a></h1>
<p>This document provides the details about how traffic light perception functions in Apollo 2.0.</p>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="永久链接至标题">¶</a></h2>
<p>The Traffic Light Perception Module is designed to provide accurate and comprehensive traffic light status using cameras.</p>
<p>Typically, the traffic light has three states:</p>
<ul class="simple">
<li><p>Red</p></li>
<li><p>Yellow</p></li>
<li><p>Green</p></li>
</ul>
<p>However, if the traffic light is not working, it might display the color black or show a flashing red or yellow light. Sometimes the traffic light cannot be found in the camera’s field of vision and the module fails to recognize its status.</p>
<p>To account for all situations, the Traffic Light Perception Module provides output for five states:</p>
<ul class="simple">
<li><p>Red</p></li>
<li><p>Yellow</p></li>
<li><p>Green</p></li>
<li><p>Black</p></li>
<li><p>Unknown</p></li>
</ul>
<p>The module’s HD-Map queries repeatedly to know whether there are lights present in front of the vehicle. The traffic light is represented by the four points on its boundary, which can be obtained by querying the HD-Map, given the car’s location. The traffic light is projected from world coordinates to image coordinates if there is a light in front of the vehicle.</p>
<p>Apollo has determined that using a single camera, which has a constant field of vision, cannot see traffic lights everywhere. This limitation is due to the following factors:</p>
<ul class="simple">
<li><p>The perception range should be above 100 meters</p></li>
<li><p>The height of the traffic lights or the width of crossing varies widely</p></li>
</ul>
<p>Consequently, Apollo 2.0 uses two cameras to enlarge its perception range:</p>
<ul class="simple">
<li><p>A <strong>telephoto</strong> <strong>camera</strong>, whose focus length is 25 mm, is installed to observe forward, distant traffic lights. Traffic lights that are captured in a telephoto camera are very large and easy to detect. However, the field of vision of a telephoto camera is quite limited. The lights are often outside of the image if the lane is not straight enough, or if the car is in very close proximity to the light.</p></li>
<li><p>A <strong>wide-angle camera</strong>, whose focus length is 6 mm, is equipped to provide a supplementary field of vision.</p></li>
</ul>
<p>The module decides which camera to use adaptively based on the light projection. Although there are only two cameras on the Apollo car, the algorithm can handle multiple cameras.</p>
<p>The following photos show the detection of traffic lights using a telephoto camera (for the first photo) and a wide-angle camera (for the second photo).</p>
<p><img alt="telephoto camera" src="../../_images/long.jpg" /></p>
<p><img alt="wide angle camera" src="../../_images/short.jpg" /></p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="pipeline">
<h1>Pipeline<a class="headerlink" href="#pipeline" title="永久链接至标题">¶</a></h1>
<p>The Pipeline has two main parts and is described in following sections:</p>
<ul class="simple">
<li><p>Pre-process</p>
<ul>
<li><p>Traffic light projection</p></li>
<li><p>Camera selection</p></li>
<li><p>Image and cached lights sync</p></li>
</ul>
</li>
<li><p>Process</p>
<ul>
<li><p>Rectify — Provide the accurate traffic light bounding boxes</p></li>
<li><p>Recognize — Provide the color of each bounding box</p></li>
<li><p>Revise — Correct the color based on the time sequence</p></li>
</ul>
</li>
</ul>
<section id="pre-process">
<h2>Pre-process<a class="headerlink" href="#pre-process" title="永久链接至标题">¶</a></h2>
<p>There is no need to detect lights in every frame of an image. The status of a traffic light changes in low frequency and the computing resources are limited. Normally, images from different cameras would arrive almost simultaneously, and only one is fed to the Process part of the Pipeline. Therefore, the selection and the matching of images are necessary.</p>
<section id="input-output">
<h3>Input/Output<a class="headerlink" href="#input-output" title="永久链接至标题">¶</a></h3>
<p>This section describes the input and the output of the Pre-process module. The input is obtained by subscribing to topic names from Apollo or directly reading them from locally stored files, and the output is fed to the successive Process module.</p>
<section id="input">
<h4>Input<a class="headerlink" href="#input" title="永久链接至标题">¶</a></h4>
<ul class="simple">
<li><p>Images from different cameras, acquired by subscribing to the topic name:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">/apollo/sensor/camera/traffic/image_long</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">/apollo/sensor/camera/traffic/image_short</span></code></p></li>
</ul>
</li>
<li><p>Localization, acquired by querying the topic:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">/tf</span></code></p></li>
</ul>
</li>
<li><p>HD Map</p></li>
<li><p>Calibration results</p></li>
</ul>
</section>
<section id="output">
<h4>Output<a class="headerlink" href="#output" title="永久链接至标题">¶</a></h4>
<ul class="simple">
<li><p>Image from the selected camera</p></li>
<li><p>Traffic light bounding box projected from world coordinates to image coordinates</p></li>
</ul>
</section>
</section>
<section id="camera-selection">
<h3>Camera Selection<a class="headerlink" href="#camera-selection" title="永久链接至标题">¶</a></h3>
<p>The traffic light is represented by a unique ID and four points on its boundary, each of which is described as a 3D point in the world coordinate system.</p>
<p>The following example shows a typical entry for traffic light <code class="docutils literal notranslate"><span class="pre">signal</span> <span class="pre">info</span></code>. The four boundary points can be obtained by querying the HD Map, given the car’s location.</p>
<div class="highlight-protobuf notranslate"><div class="highlight"><pre><span></span><span class="n">signal</span> <span class="n">info</span><span class="o">:</span>
<span class="n">id</span> <span class="p">{</span>
  <span class="n">id</span><span class="o">:</span> <span class="s">&quot;xxx&quot;</span>
<span class="p">}</span>
<span class="n">boundary</span> <span class="p">{</span>
  <span class="n">point</span> <span class="p">{</span> <span class="n">x</span><span class="o">:</span> <span class="o">...</span>  <span class="n">y</span><span class="o">:</span> <span class="o">...</span>  <span class="n">z</span><span class="o">:</span> <span class="o">...</span>  <span class="p">}</span>
  <span class="n">point</span> <span class="p">{</span> <span class="n">x</span><span class="o">:</span> <span class="o">...</span>  <span class="n">y</span><span class="o">:</span> <span class="o">...</span>  <span class="n">z</span><span class="o">:</span> <span class="o">...</span>  <span class="p">}</span>
  <span class="n">point</span> <span class="p">{</span> <span class="n">x</span><span class="o">:</span> <span class="o">...</span>  <span class="n">y</span><span class="o">:</span> <span class="o">...</span>  <span class="n">z</span><span class="o">:</span> <span class="o">...</span>  <span class="p">}</span>
  <span class="n">point</span> <span class="p">{</span> <span class="n">x</span><span class="o">:</span> <span class="o">...</span>  <span class="n">y</span><span class="o">:</span> <span class="o">...</span>  <span class="n">z</span><span class="o">:</span> <span class="o">...</span>  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The boundary points in the 3D world coordinates are then projected to the 2D image coordinates of each camera. For one traffic light, the bounding box described by the four projected points in the telephoto camera image has a larger area. It is better for detection than that in the wide-range image. Consequently,  the image from the camera with the longest focal length that can see all the lights will be selected as the output image. The traffic light bounding box projected on this image will be the output bounding box.</p>
<p>The selected camera ID with timestamp is cached in queue, as shown below:</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="k">struct</span> <span class="nc">ImageLights</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w"> </span><span class="n">CarPose</span><span class="w"> </span><span class="n">pose</span><span class="p">;</span><span class="w"></span>
<span class="w"> </span><span class="n">CameraId</span><span class="w"> </span><span class="n">camera_id</span><span class="p">;</span><span class="w"></span>
<span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">timestamp</span><span class="p">;</span><span class="w"></span>
<span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">num_signal</span><span class="p">;</span><span class="w"></span>
<span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="n">other</span><span class="w"> </span><span class="p">...</span><span class="w"></span>
<span class="p">};</span><span class="w"></span>
</pre></div>
</div>
<p>Thus far, all the information that we need includes the localization, the calibration results, and the HD Map. The selection can be performed at any time as the projection is independent of the image content. The task of performing the selection when images arrive is just for simplicity. Moreover, image selection does not need to be performed upon the arrival of every image, and a time interval for the selection is set.</p>
</section>
<section id="image-sync">
<h3>Image Sync<a class="headerlink" href="#image-sync" title="永久链接至标题">¶</a></h3>
<p>Images arrive with a timestamp and a camera ID. The pairing of a timestamp and a camera ID is used to find the appropriate cached information. If the image can find a cached record with same camera ID and a small difference between timestamps, the image can be published to the Process module. All inappropriate images are abandoned.</p>
</section>
</section>
<section id="process">
<h2>Process<a class="headerlink" href="#process" title="永久链接至标题">¶</a></h2>
<p>The Process module is divided into three steps, with each step focusing on one task:</p>
<ul class="simple">
<li><p>Rectifier — Detects a traffic light bounding box in a ROI.</p></li>
<li><p>Recognizer— Classifies the bounding box’s color.</p></li>
<li><p>Reviser — Correct color using sequential information.</p></li>
</ul>
<section id="id1">
<h3>Input/Output<a class="headerlink" href="#id1" title="永久链接至标题">¶</a></h3>
<p>This section describes the data input and output of the Process. The input is obtained from the Pre-process module and the output is published as a traffic light topic.</p>
<section id="id2">
<h4>Input<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h4>
<ul class="simple">
<li><p>Image from a selected camera</p></li>
<li><p>A set of bounding boxes</p></li>
</ul>
</section>
<section id="id3">
<h4>Output<a class="headerlink" href="#id3" title="永久链接至标题">¶</a></h4>
<ul class="simple">
<li><p>A set of bounding boxes with color labels.</p></li>
</ul>
</section>
</section>
<section id="rectifier">
<h3>Rectifier<a class="headerlink" href="#rectifier" title="永久链接至标题">¶</a></h3>
<p>The projected position, which is affected by the calibration, localization, and the HD-Map label, is <em><strong>not completely reliable</strong></em>. A larger region of interest (ROI), calculated using the projected light’s position, is used to find the accurate boundingbox for the traffic light.</p>
<p>In the photo below, the blue rectangle indicates the projected light bounding box, which has a large offset to the actual light. The big, yellow rectangle is the ROI.</p>
<p><img alt="example" src="../../_images/example.jpg" /></p>
<p>The traffic light detection is implemented as a regular convolutional neural network (CNN) detection task. It receives an image with an ROI as input, and serial bounding boxes as output. There might be more lights in the ROI than those in input.</p>
<p>Apollo needs to select the proper lights according to the detection score, and the input lights’ position and shape. If the CNN network cannot find any lights in the ROI, the status from the input lights is marked as unknown and the two remaining steps (Recognizer and Reviser) are skipped.</p>
</section>
<section id="recognizer">
<h3>Recognizer<a class="headerlink" href="#recognizer" title="永久链接至标题">¶</a></h3>
<p>The traffic light recognition is implemented as a typical CNN classification task. The network receives an image with a ROI and a list of bounding boxes as input. The output of network is a <code class="docutils literal notranslate"><span class="pre">$4\times</span> <span class="pre">n$</span> <span class="pre">vector</span></code>, representing four probabilities for each box to be black, red, yellow, and green.</p>
<p>The class with maximum probability will be regarded as the light’s status, if and only if the probability is large enough. Otherwise, the light’s status will be set to black, which means that the status is not certain.</p>
</section>
<section id="reviser">
<h3>Reviser<a class="headerlink" href="#reviser" title="永久链接至标题">¶</a></h3>
<p>Because a traffic light can be flashing or shaded, and the Recognizer is <em><strong>not</strong></em> perfect, the current status may fail to represent the real status. A Reviser that could correct the status is necessary.</p>
<p>If the Reviser receives a definitive status such as red or green, the Reviser saves and outputs the status directly. If the received status is black or unknown, the Reviser looks up the saved map. When the status of this light is certain for a period of time, the Reviser outputs this saved status. Otherwise, the status of black or unknown is sent as output.</p>
<p>Because of the time sequence, yellow only exists <em><strong>after</strong></em> green and <em><strong>before</strong></em> red. Any yellow <em><strong>after red</strong></em> is reset to red for the sake of safety until green displays.</p>
</section>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>导航</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="总目录"
             >索引</a></li>
        <li class="right" >
          <a href="traffic_light_cn.html" title="交通信号灯感知"
             >下一页</a> |</li>
        <li class="right" >
          <a href="reference_line_smoother_cn.html" title="参考线平滑设定"
             >上一页</a> |</li>
        <li><a href="../../index.html">Apollo home</a>&#160;|</li>
        <li><a href="../../contents.html">Documentation</a> &#187;</li>

        <li class="nav-item nav-item-this"><a href="">Traffic Light Perception</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; 版权所有 2021, xinetzone.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.2.0.
    </div>
  </body>
</html>